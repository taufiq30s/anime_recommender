# -*- coding: utf-8 -*-
"""Recomendation_System_MLT_Dicoding_Moonchild.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EhOmG6Oj84j0oWgVBcRt_mUJbmLGflc8

# Import Modules
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from tensorflow.keras.layers import Input, Add, Activation, Lambda, Embedding, Reshape, Dot

"""# Data Understanding

## Import and Load Dataset
"""

# !pip install -q kaggle
# !mkdir ~/.kaggle/
# !cp /notebooks/kaggle.json ~/.kaggle/
# !chmod 600 ~/.kaggle/kaggle.json
# !kaggle datasets download -d "hernan4444/anime-recommendation-database-2020"
# !unzip anime-recommendation-database-2020.zip

"""## Dataset Description

Dataset ini berisi informasi _anime_ sebanyak 17.562 dan pengguna sebesar 325.772 dimana informasi yang disimpan sebagai berikut.

* Daftar _anime_ per pengguna, termasuk _anime_ yang status _dropped_, ditamatin, direncakan untuk di tonton, sedang di tonton atau _on hold_
* Rating yang diberikan oleh pengguna terhadap _anime_ yang sudah tamat di tonton, sedang di tonton ataupun _on hold_
* Informasi mengenai _anime_ seperti _genre, stats, studio_, dan sebagainya
* _HTML file_ dengan informasi _anime_ hasil _scrapping_

Untuk file _csv_, terdapat 5 file _csv_, yaitu
1. `anime.csv`
2. `anime_with_synopsis.csv`
3. `animelist.csv`
4. `rating_complete.csv`
5. `watching_status.csv`
"""

anime_df = pd.read_csv('anime.csv')
anime_sypnopsis_df = pd.read_csv('anime_with_synopsis.csv')
anime_list_df = pd.read_csv('animelist.csv')
rating_complete_df = pd.read_csv('rating_complete.csv')
watching_status_df = pd.read_csv('watching_status.csv')

print('Jumlah Seluruh Data Anime :', len(anime_df.MAL_ID.unique()))
print('Jumlah Data Anime dengan Sinopsis :', len(anime_sypnopsis_df.MAL_ID.unique()))
print('Jumlah Data Anime yang Ditambah User :', len(anime_list_df.anime_id.unique()))
print('Jumlah Data Anime yang Dirating User Setelah Tamat :',
      len(rating_complete_df.anime_id.unique()))

"""# Univariate Exploratory Data Analysis

Variabel-variabel pada dataset ini adalah

* **anime_df** - Berisi informasi _anime_ secara general seperti _genre, stats, studio_, dan sebagainya
* **anime_sypnopsis_df** - Berisi informasi _anime_ yang lebih ringkas dibandingkan dengan **anime_df** namun ditambah dengan sinopsis setiap _anime_
* **anime_list_df** - Berisi daftar _anime_ yang didaftarkan oleh pengguna dengan skor _rating_, status _watching_ dan jumlah episode yang sudah ditonton
* **rating_complete_df** - Berisi daftar _rating_ setiap _anime_ dengan _watching status_ adalah **2** yang berarti tamat ditonton
* **watching_status_df** - Berisi daftar kode status _watching_ untuk kolom "watching_list" di variabel **anime_list_df**
"""

raw_anime_mask = ['Name', 'Score', 'Genres', 'Type', 'Episodes', 'Aired', 'Premiered']

"""## Anime"""

anime_df.info()

"""Berdasarkan variabel dari _file anime_, terdapat 17562 data dan terdapat 35 kolom dimana variabel dimana penjelasan kolomnya adalah sebagai berikut

* **MAL_ID** : ID _anime_ yang dicatat di _MyAnimeList_
* **Name** : Judul lengkap _anime_
* **Score** : _Rating_ rata-rata dari seluruh pengguna yang telah menilai _anime_ tersebut
* **Genres** : Kumpulan _genre_ dari sebuah _anime_
* **English name** : Judul _anime_ dalam Bahasa Inggris
* **Japanese name** : Judul _anime_ dalam aksara Jepang
* **Type** : Tipe/format penayangan _anime_, seperti **TV, Movie, OVA**
* **Episodes** : Jumlah episode
* **Aired** : Tanggal rilis/penayangan perdana
* **Premiered** : Musim penayangan perdana
* **Producers** : Produser yang menaungin produksi _anime_
* **Studios** : Studio utama _anime_ tersebut diproduksi
* **Source** : Sumber material dari _anime_, seperti _Manga, Visual Novel, Light Novel_ atau _Original_
* **Duration** : Durasi _anime_ dalam sekali tayang per episode
* **Rating** : _Rating_ usia penonton
* **Ranked** : Posisi ranking berdasarkan skor _rating_ rata-rata
* **Popularity** : Posisi popularitas berdasarkan jumlah pengguna yang menambahkan _anime_ tersebut di dalam daftar _anime_-nya
* **Members** : Jumlah pengguna yang menambahkan _anime_ tersebut di daftar _anime_ pada akun mereka
* **Favorites** : Jumlah pengguna yang memfavoritkan _anime_ tersebut
* **Watching** : Jumlah pengguna yang menonton _anime_ tersebut
* **Completed** : Jumlah pengguna yang menamatkan _anime_ tersebut
* **On-Hold** : Jumlah pengguna yang berhenti sementara menonton _anime_ tersebut
* **Dropped** : Jumlah pengguna yang tidak melanjutkan menonton _anime_ tersebut
* **Plan to Watch** : Jumlah pengguna yang berencana menonton _anime_ tersebut
* **Score-10** : Jumlah pengguna yang memberikan skor / _rating_ dengan nilai 10
* **Score-9** : Jumlah pengguna yang memberikan skor / _rating_ dengan nilai 9
* **Score-8** : Jumlah pengguna yang memberikan skor / _rating_ dengan nilai 8
* **Score-7** : Jumlah pengguna yang memberikan skor / _rating_ dengan nilai 7
* **Score-6** : Jumlah pengguna yang memberikan skor / _rating_ dengan nilai 6
* **Score-5** : Jumlah pengguna yang memberikan skor / _rating_ dengan nilai 5
* **Score-4** : Jumlah pengguna yang memberikan skor / _rating_ dengan nilai 4
* **Score-3** : Jumlah pengguna yang memberikan skor / _rating_ dengan nilai 3
* **Score-2** : Jumlah pengguna yang memberikan skor / _rating_ dengan nilai 2
* **Score-1** : Jumlah pengguna yang memberikan skor / _rating_ dengan nilai 1

## Anime With Sypnopsis
"""

anime_sypnopsis_df.info()

"""Berdasarkan dari variabel berikut, terdapat 16214 data dan terdapat 5 kolom dimana variabel dimana penjelasan kolomnya adalah sebagai berikut

* **MAL_ID** : ID _anime_ yang dicatat di _MyAnimeList_
* **Name** : Judul lengkap _anime_
* **Score** : _Rating_ rata-rata dari seluruh pengguna yang telah menilai _anime_ tersebut
* **Genres** : Kumpulan _genre_ dari sebuah _anime_
* **synopsis** : Sinopsis dari _anime_

## Anime List
"""

anime_list_df.info()

"""Berdasarkan dari variabel berikut, jika melihat dari _RangeIndex_ terdapat 109.224.747 data dan terdapat 5 kolom dimana variabel dimana penjelasan kolomnya adalah sebagai berikut

* **user_id** : ID pengguna secara _random_ dan tidak terkait dengan id pengguna di _MyAnimeList_
* **anime_id** : ID _anime_ di _MyAnimeList_
* **score** : Skor atau _rating_ yang diberi pengguna terhadap _anime_ tersebut. Skor 0 menunjukkan pengguna tidak memberikan skor/_rating_
* **watching_status** : ID Status nonton dari pengguna berdasarkan variabel **watching_status_df**
* **watched_episodes** : Jumlah episode yang sudah ditonton pengguna

## Watching Status
"""

watching_status_df.info()

"""Berdasarkan dari variabel berikut, terdapat 5 data dan terdapat 2 kolom dimana variabel dimana penjelasan kolomnya adalah sebagai berikut

* **status** : ID status nonton dari pengguna untuk kolom "watching_status" di variabel **anime_list_df**
* **description** : Deskripsi dari ID status

Variabel ini dipakai sebagai _indexing_ atau penanda untuk kolom "watching_status" di variabel **anime_list_df**

## Rating Complete
"""

rating_complete_df.info()

"""Berdasarkan dari variabel berikut, terdapat 57.633.278 data dan terdapat 3 kolom dimana variabel dimana penjelasan kolomnya adalah sebagai berikut

* **user_id** : ID pengguna secara _random_ dan tidak terkait dengan id pengguna di _MyAnimeList_
* **anime_id** : ID _anime_ di _MyAnimeList_
* **rating** : _rating_ atau skor yang diberikan pengguna

## Top 20 Anime Berdasarkan Popularitas
"""

top_20_popular = anime_df[anime_df['Popularity'] > 0].sort_values(by='Popularity', ascending=True).head(20)
top_20_popular[raw_anime_mask]

top_20_popular.describe()

print(top_20_popular[raw_anime_mask+['Popularity']].to_markdown())

"""## Top 20 Anime yang Paling Banyak Ditamatin"""

anime_df.sort_values(by='Completed', ascending=False).head(20).plot(
    x='Name', y='Completed', kind='bar', figsize=(15,6), title='Top 20 Anime Paling Banyak Ditamatin')

anime_df[raw_anime_mask+['Completed']].sort_values(by='Completed', ascending=False).head(20)

anime_df[raw_anime_mask+['Completed']].sort_values(by='Completed', ascending=False).head(20).describe()

print(anime_df[raw_anime_mask+['Completed']].sort_values(by='Completed', ascending=False).head(20).to_markdown())

"""## Top 20 Anime yang Paling Banyak Di-Drop"""

anime_df.sort_values(by='Dropped', ascending=False).head(20).plot(
    x='Name', y='Dropped', kind='bar', figsize=(15,6), title='Top 20 Anime Paling Banyak Di-Drop')

anime_df[raw_anime_mask+['Dropped']].sort_values(by='Dropped', ascending=False).head(20)

anime_df[raw_anime_mask+['Dropped']].sort_values(by='Dropped', ascending=False).head(20).describe()

print(anime_df[raw_anime_mask+['Dropped']].sort_values(by='Dropped', ascending=False).head(20).to_markdown())

"""## Distribusi Anime Berdasarkan Musim Penayangan"""

anime_df['season'] = anime_df.loc[anime_df['Premiered'] != 'Unknown', 'Premiered'].str.split().str[0]
anime_df['season'].value_counts().plot(
    kind='pie', figsize=(8, 8), autopct='%1.1f%%', title='Distribusi Anime berdasarkan Musim Penayangan')

print(anime_df['season'].value_counts())

"""## Top 20 Anime yang Paling Banyak Ditambahkan Ke Daftar Anime"""

anime_df.sort_values(by='Members', ascending=False).head(20).plot(
    x='Name', y='Members', xlabel='Title', kind='bar', figsize=(15,6), title='Top 20 Anime Paling Banyak Ditambahkan Ke Daftar Anime')

anime_df[raw_anime_mask+['Members']].sort_values(by='Members', ascending=False).head(20)

print(anime_df[raw_anime_mask+['Members']].sort_values(by='Members', ascending=False).head(20).to_markdown())

"""## Score Feature"""

anime_df['Score'].unique()

## Ganti Score dengan nilai "Unknown" dengan Skor rata-rata seluruh anime
scores = anime_df['Score'][anime_df['Score'] != 'Unknown']
scores = scores.astype('float')
score_mean= round(scores.mean() , 2)
anime_df['Score'] = anime_df['Score'].replace('Unknown', score_mean)

## Konversi tipe data Score ke float64
anime_df['Score'] = anime_df['Score'].astype('float64')

## Clear Memories
del scores
del score_mean

plt.hist(anime_df['Score'], bins=10, edgecolor='black')

# Set the labels and title
plt.xlabel('Score')
plt.ylabel('Frequency')
plt.title('Score Distribution')

# Set the x-axis limits and ticks
plt.xlim(1, 10)
plt.xticks(range(1, 11))

# Display the plot
plt.show()

"""## Top 20 Anime berdasarkan Score"""

anime_df[raw_anime_mask].sort_values(by='Score', ascending=False).head(20)

print(anime_df[raw_anime_mask].sort_values(by='Score', ascending=False).head(20).to_markdown())

"""## Deskripsi Kolom Score dan Members"""

anime_df[['Score', 'Members']].describe().apply(lambda s: s.apply('{0:.5f}'.format))

print(anime_df[['Score', 'Members']].describe().apply(lambda s: s.apply('{0:.5f}'.format)).to_markdown())

"""## Genres Feature"""

def showGenreList(df):
    # Split the genres in each row and create a list of individual genres
    genre_lists = df['Genres'].str.split(', ')

    # Flatten the list of lists
    flattened_genres = [genre for genres in genre_lists for genre in genres]

    # Get the unique genres
    unique_genres = pd.Series(flattened_genres).unique()

    # Display the unique genres
    print(unique_genres)

    print("\nTotal\n")
    print(df['Genres'].str.split(', ').explode().value_counts().to_markdown())

def showGenrePlot(df):
  # Count the occurrences of each genre
  genre_counts = df['Genres'].str.split(', ').explode().value_counts()

  # Create the bar plot
  plt.figure(figsize=(15, 6))
  plt.bar(genre_counts.index, genre_counts.values, width=0.6)

  # Set the labels and title
  plt.xlabel('Genre')
  plt.ylabel('Count')
  plt.title('Genre Distribution')

  # Rotate the x-axis labels for better readability
  plt.xticks(rotation=90)

  # Display the plot
  plt.show()

showGenreList(anime_df)

showGenrePlot(anime_df)

"""## Type Feature"""

type_counts = anime_df['Type'].value_counts()

# Create a bar chart
plt.bar(type_counts.index, type_counts.values, color = ['red', 'yellow', 'black', 'blue', 'orange', 'green', 'purple'])
plt.title('Jumlah Judul Anime Berdasarkan Tipe')

plt.show()

print("Jumlah judul anime berdasarkan tipe")
print(anime_df['Type'].value_counts().to_markdown())
print("\nJumlah judul anime berdasarkan tipe")
print((100*anime_df['Type'].value_counts(normalize=True)).to_markdown())

"""## Watching Status Feature"""

anime_list_df.head()

for index, row in watching_status_df.iterrows():
  print(row.status, row[' description'])

anime_list_df['watching_status'].unique()

print(anime_list_df['watching_status'].value_counts().to_markdown())

"""## Normalisasi ID Watching Status"""

# Ubah id 5 menjadi 6 (ambil yang terdekat)
anime_list_df['watching_status'] = anime_list_df['watching_status'].replace(
    5, 6
)

# Ubah id 33 menjadi 3
anime_list_df['watching_status'] = anime_list_df['watching_status'].replace(
    33, 3
)

# Ubah id 55 menjadi 6
anime_list_df['watching_status'] = anime_list_df['watching_status'].replace(
    55, 6
)

anime_list_df['watching_status'].unique()

print(anime_list_df['watching_status'].value_counts().to_markdown())

"""### Periksa data dengan ID Watching Status 0"""

anime_list_df.loc[anime_list_df['watching_status'] == 0].head()

print(anime_list_df.loc[anime_list_df['watching_status'] == 0].head().to_markdown())

print(anime_list_df[['rating', 'watching_status', 'watched_episodes']].loc[anime_list_df['watching_status'] == 0].describe().to_markdown())

print(anime_list_df[['rating', 'watching_status', 'watched_episodes']].loc[
    (anime_list_df['watching_status'] == 0)
    & ((anime_list_df['rating'] > 0) |
      (anime_list_df['watched_episodes'] > 0))].head().to_markdown())

len(anime_list_df)

anime_list_df = anime_list_df[anime_list_df['watching_status'] != 0]

len(anime_list_df)

"""### Ubah 'watching_status' dari ID menjadi sesuai 'description' di watching_status_df"""

for index, row in watching_status_df.iterrows():
  anime_list_df.loc[:, 'watching_status'] = anime_list_df['watching_status'].replace(
      row.status, row[' description'])

## Clear Memory
del watching_status_df

print("Jumlah user terhadap status tonton")
with pd.option_context('display.float_format', '{:.0f}'.format):
    count = anime_list_df['watching_status'].value_counts()
print(count)
print("\nPersentase jumlah user terhadap status tonton")
print((100*anime_list_df['watching_status'].value_counts(normalize=True)).to_markdown())
print("\nDiagram")
anime_list_df['watching_status'].value_counts().plot(kind='bar', title='Watching Status', figsize=(16,8))

"""# Data Preparation

## Hapus Anime dengan Genre Tertentu
"""

## Hapus list anime dengan genre "dewasa" dan "Unknown"
genres_to_remove = ['Hentai', 'Yuri', 'Yaoi', 'Shounen Ai',
                    'Shoujo Ai', 'Ecchi', 'Unknown']
mask = anime_df['Genres'].str.contains('|'.join(genres_to_remove))
anime_df = anime_df[~mask]

showGenreList(anime_df)

len(anime_df)

"""## Hapus Kolom yang Tidak Dibutuhkan di variabel anime"""

anime_df = anime_df[['MAL_ID', 'Name', 'Score', 'Genres', 'Type', 'Members']]

"""## Gabungkan Data Anime dengan Sinopsis"""

anime_df = anime_df.merge(anime_sypnopsis_df[['MAL_ID', 'sypnopsis']], on='MAL_ID')
anime_df.head()

print(anime_df.head().to_markdown())

"""## Data Preparation Untuk Content Based Filtering

### Filter Daftar Anime Berdasarkan Jumlah Members
"""

anime_top_df = anime_df.loc[anime_df['Members'] >= 34658]
len(anime_top_df)

anime_top_df.head()

print(anime_top_df.head().to_markdown())

"""## Data Preparation Untuk Colaborative Filtering

### Filter Ranking User Jika User Telah Menamatkan atau Berhenti Menonton Anime Tersebut
"""

anime_list_df = anime_list_df.loc[anime_list_df['watching_status'].isin(['Completed', 'Dropped'])]

anime_list_df['watching_status'].unique()

"""### Cek Data yang NaN"""

print(anime_list_df.isnull().sum().to_markdown())

"""### Encode Fitur user_id dan anime_id"""

# Mengubah anime_id menjadi list tanpa nilai yang sama
user_ids = anime_list_df.user_id.unique().tolist()
# Melakukan encoding anime_id
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
# Melakukan proses encoding angka ke ke anime_id
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}

# Mengubah anime_id menjadi list tanpa nilai yang sama
anime_ids = anime_list_df.anime_id.unique().tolist()
# Melakukan proses encoding anime_id
anime_to_anime_encoded = {x: i for i, x in enumerate(anime_ids)}
# Melakukan proses encoding angka ke anime_id
anime_encoded_to_anime = {i: x for i, x in enumerate(anime_ids)}

# Mapping user_id ke dataframe user
anime_list_df['user'] = anime_list_df['user_id'].map(user_to_user_encoded)

# Mapping anime_id ke dataframe anime
anime_list_df['anime'] = anime_list_df['anime_id'].map(anime_to_anime_encoded)

anime_list_df.head()

print(anime_list_df.head().to_markdown())

"""### Convert Fitur Rating"""

anime_list_df['rating'] = anime_list_df['rating'].astype('float64')
anime_list_df.head()

anime_list_df.info()

"""### Periksa Jumlah Data User, Anime dan Rating Minimum dan Maksimum"""

min_rating = min(anime_list_df['rating'])
max_rating = max(anime_list_df['rating'])
num_users = len(user_to_user_encoded)
num_animes = len(anime_to_anime_encoded)

print('Number of User: {}, Number of Animes: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_animes,
    min_rating, max_rating
))

"""### Train-Test Split"""

## Acak data
anime_list_df = anime_list_df.sample(frac=1, random_state=42)
anime_list_df.head()

print(anime_list_df.head().to_markdown())

# Membuat variabel x untuk mencocokkan data user dan anime menjadi satu value
x = anime_list_df[['user', 'anime']].values

# Membuat variabel y untuk membuat rating dari hasil
y = anime_list_df['rating'].apply(lambda x: (
    x - min_rating) / (
    max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * anime_list_df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""# Modelling

## Content Based Filtering

### TF-IDF Vectorizer
"""

# Inisialisasi TfidfVectorizer
tfid = TfidfVectorizer(tokenizer=lambda x: x.lower().split(', '))

# Melakukan perhitungan idf pada data Genre
tfid.fit(anime_top_df['Genres'])

# Mapping array dari fitur index integer ke fitur judul anime
tfid.get_feature_names_out()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tfid.fit_transform(anime_top_df['Genres'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan genre
# Baris diisi dengan judul anime

tfid_example = pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=anime_top_df.Name
).sample(22, axis=1).sample(10, axis=0)

tfid_example

tfid_example.to_markdown()

"""### Cosine Similarity"""

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa judul anime
cosine_sim_df = pd.DataFrame(cosine_sim, index=anime_top_df.Name, columns=anime_top_df.Name)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

print(cosine_sim_df.sample(5, axis=1).sample(10, axis=0).to_markdown())

"""### Euclidean Distance"""

# Menghitung euclidean distance pada matrix tf-idf
euclidean_dist = euclidean_distances(tfidf_matrix)
# Membuat dataframe dari variabel euclidean_dist dengan baris dan kolom berupa judul anime
euclidean_dist_df = pd.DataFrame(euclidean_dist, index=anime_top_df.Name, columns=anime_top_df.Name)

euclidean_dist_df.sample(5, axis=1).sample(10, axis=0)

print(euclidean_dist_df.sample(5, axis=1).sample(10, axis=0).to_markdown())

"""## Collaborative Filtering

### RecommenderNet Model 1
"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_anime, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_anime = num_anime
    self.embedding_size = embedding_size
    self.user_embedding = tf.keras.layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = tf.keras.regularizers.l2(1e-6)
    )
    self.user_bias = tf.keras.layers.Embedding(num_users, 1) # layer embedding user bias
    self.anime_embedding = tf.keras.layers.Embedding( # layer embeddings anime
        num_anime,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = tf.keras.regularizers.l2(1e-6)
    )
    self.anime_bias = tf.keras.layers.Embedding(num_anime, 1) # layer embedding anime bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    resto_vector = self.anime_embedding(inputs[:, 1]) # memanggil layer embedding 3
    resto_bias = self.anime_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_resto = tf.tensordot(user_vector, resto_vector, 2)

    x = dot_user_resto + user_bias + resto_bias

    return tf.nn.sigmoid(x) # activation sigmoid

model_v1_1 = RecommenderNet(num_users, num_animes, 50)
model_v1_1.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

callbacks_1_1=[
    tf.keras.callbacks.EarlyStopping(
        patience=3,
        restore_best_weights=True,
        monitor ='val_root_mean_squared_error' ,
    ),
    tf.keras.callbacks.ModelCheckpoint(
        '/notebooks/model_1_1/cp.ckpt',
        'val_root_mean_squared_error', 1, True, True),
]

history_v1_1 = model_v1_1.fit(
    x = x_train,
    y = y_train,
    batch_size = 8192,
    epochs = 100,
    validation_data = (x_val, y_val),
    callbacks=callbacks_1_1,
    verbose=1
)

plt.plot(history_v1_1.history['root_mean_squared_error'])
plt.plot(history_v1_1.history['val_root_mean_squared_error'])
plt.title('Model Metrics (Optimizer Adam lr. 0.001)')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

model_v1_2 = RecommenderNet(num_users, num_animes, 50)
model_v1_2.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = tf.optimizers.RMSprop(1e-4),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

callbacks_1_2=[
    tf.keras.callbacks.EarlyStopping(
        patience=3,
        restore_best_weights=True,
        monitor ='val_root_mean_squared_error' ,
    ),
    tf.keras.callbacks.ModelCheckpoint(
        '/notebooks/model_1_2/cp.ckpt',
        'val_root_mean_squared_error', 1, True, True),
]

history_v1_2 = model_v1_2.fit(
    x = x_train,
    y = y_train,
    batch_size = 8192,
    epochs = 100,
    validation_data = (x_val, y_val),
    callbacks=callbacks_1_2,
    verbose=1
)

plt.plot(history_v1_2.history['root_mean_squared_error'])
plt.plot(history_v1_2.history['val_root_mean_squared_error'])
plt.title('Model 1 Metrics (Optimizer RMSprop lr. 0.0001)')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""# Evaluation

## Content Based Filtering

### Create Prediction Function
"""

anime_columns = ['MAL_ID', 'Name', 'Score', 'Genres', 'Type']
def get_recommendations(title, similarity_data=cosine_sim_df, similar_type='cosine', items=anime_top_df[anime_columns], k=10):
    """
    Rekomendasi Resto berdasarkan kemiripan dataframe

    Parameter:
    ---
    nama_resto : tipe data string (str)
                Nama Restoran (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan resto sebagai
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---


    Pada index ini, kita mengambil k dengan nilai similarity terbesar
    pada index matrix yang diberikan (i).
    """


    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)


    # Mengambil data dengan similarity terbesar (cosine) dan terkecil (euclidean) dari index yang ada
    if (similar_type == 'cosine'):
        index = similarity_data.loc[:,title].to_numpy().argpartition(
        range(-1, -k, -1))
        closest = similarity_data.columns[index[-1:-(k+2):-1]]
        score = similarity_data.iloc[index[-1:-(k+2):-1],
                                     similarity_data.columns.get_loc(title)
                                    ].reset_index(drop=True)
    else:
        index = similarity_data.loc[:,title].to_numpy().argpartition(
        range(k+1))
        closest = similarity_data.columns[index[:(k+2)]]
        score = similarity_data.iloc[index[:(k+2)],
                                     similarity_data.columns.get_loc(title)
                                    ].reset_index(drop=True)

    # Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(title, errors='ignore')
    result = pd.DataFrame(closest).merge(items).head(k)
    result['score'] = score
    return result

"""#### Example Titles"""

anime_top_df.loc[anime_top_df.Name.isin([
    'Clannad: After Story',
    'Non Non Biyori',
    'Sword Art Online',
    'Kuma Kuma Kuma Bear',
    'Gochuumon wa Usagi Desu ka?'
]), anime_columns]

print(anime_top_df.loc[anime_top_df.Name.isin([
    'Clannad: After Story',
    'Non Non Biyori',
    'Sword Art Online',
    'Kuma Kuma Kuma Bear',
    'Gochuumon wa Usagi Desu ka?'
]), anime_columns].to_markdown())

"""#### Cosine Similarity"""

get_recommendations('Clannad: After Story')

print(get_recommendations('Clannad: After Story').to_markdown())

get_recommendations('Non Non Biyori')

print(get_recommendations('Non Non Biyori').to_markdown())

get_recommendations('Sword Art Online')

print(get_recommendations('Sword Art Online').to_markdown())

get_recommendations('Kuma Kuma Kuma Bear')

print(get_recommendations('Kuma Kuma Kuma Bear').to_markdown())

get_recommendations('Gochuumon wa Usagi Desu ka?')

print(get_recommendations('Gochuumon wa Usagi Desu ka?').to_markdown())

"""#### Euclidean Distance"""

get_recommendations('Clannad: After Story', euclidean_dist_df, 'euclidean')

print(get_recommendations('Clannad: After Story', euclidean_dist_df, 'euclidean').to_markdown())

get_recommendations('Non Non Biyori', euclidean_dist_df, 'euclidean')

print(get_recommendations('Non Non Biyori', euclidean_dist_df, 'euclidean').to_markdown())

get_recommendations('Sword Art Online', euclidean_dist_df, 'euclidean')

print(get_recommendations('Sword Art Online', euclidean_dist_df, 'euclidean').to_markdown())

get_recommendations('Kuma Kuma Kuma Bear', euclidean_dist_df, 'euclidean')

print(get_recommendations('Kuma Kuma Kuma Bear', euclidean_dist_df, 'euclidean').to_markdown())

get_recommendations('Gochuumon wa Usagi Desu ka?', euclidean_dist_df, 'euclidean')

print(get_recommendations('Gochuumon wa Usagi Desu ka?', euclidean_dist_df, 'euclidean').to_markdown())

"""## Colaborative Filtering

### Train Result
"""

fig, ax = plt.subplots(2, figsize=(16, 8))

mt1 = history_v1_1.history['root_mean_squared_error']
mv1 = history_v1_1.history['val_root_mean_squared_error']
mt2 = history_v1_2.history['root_mean_squared_error']
mv2 = history_v1_2.history['val_root_mean_squared_error']

ax[0].plot(mt1)
ax[0].plot(mv1)

ax[1].plot(mt2)
ax[1].plot(mv2)

for plot in ax.flat:
    plot.set(xlabel='rmse', ylabel='val-rmse')

plt.suptitle("Perbandingan Model dengan Optimizer Adam lr. 0,001\ndengan RMSprop lr. 0,0001")

plt.show()

"""### Load Weight"""

def get_recommended_user(markdown=False):
    user_id = anime_list_df.user_id.sample(1).iloc[0]
    ## Ambil anime yang pernah di tonton user
    watched_anime = anime_list_df[anime_list_df.user_id == user_id]

    ## Ambil data anime yang belum pernah di tonton
    # Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html
    anime_not_watched = anime_df[~anime_df['MAL_ID'].isin(watched_anime.anime_id.values)]['MAL_ID']
    anime_not_watched = list(
        set(anime_not_watched)
        .intersection(set(anime_to_anime_encoded.keys()))
    )

    ## Ambil Encoded Anime dari list anime yang belum pernah ditonton
    anime_not_watched = [[anime_to_anime_encoded.get(x)] for x in anime_not_watched]
    ## Ambil user encoded untuk user yang akan diberikan rekomendasi
    user_encoder = user_to_user_encoded.get(user_id)
    ## Set Data prediction berdasarkan encode user sekarang dengan encode anime yang belum pernah ditonton
    user_anime_array = np.hstack(
        ([[user_encoder]] * len(anime_not_watched), anime_not_watched)
    )

    ## Prediksi rating
    model_v1_2.load_weights('/notebooks/model_1_2/cp.ckpt')
    ratings = model_v1_2.predict(user_anime_array).flatten()

    ## Ambil hasil dengan rating tertinggi
    top_ratings_indices = ratings.argsort()[-10:][::-1]
    ## Ambil id anime berdasarkan hasil prediksi
    recommended_anime_ids = [
        anime_encoded_to_anime.get(anime_not_watched[x][0]) for x in top_ratings_indices
    ]

    ## Sort 10 Anime terbaik yang pernah user rating
    top_anime_user = (
        watched_anime.sort_values(
            by = 'rating',
            ascending=False
        )
        .head(10)
        .anime_id.values
    )

    anime_df_rows = anime_df[anime_df['MAL_ID'].isin(top_anime_user)]
    ## Tampilkan anime hasil prediksi dengan rating tertinggi
    recommended_anime = anime_df[anime_df['MAL_ID'].isin(recommended_anime_ids)]

    print('Showing recommendations for users: {}'.format(user_id))
    if(not markdown):
        print('===' * 9)
        print('Anime with high ratings from user')
        print('----' * 8)

        for row in anime_df_rows.itertuples():
            print(row.Name, ':', row.Genres)

        print('----' * 8)
        print('Top 10 Anime recommendation')
        print('----' * 8)


        for row in recommended_anime.itertuples():
            print(row.Name, ':', row.Genres)
    else:
        print("Top 10 Animes\n")
        print(anime_df_rows[anime_columns].to_markdown())
        print("Top 10 Animes Recommend\n")
        print(recommended_anime[anime_columns].to_markdown())

anime_columns = ['MAL_ID', 'Name', 'Score', 'Genres', 'Type']

"""### Predict"""

get_recommended_user()

# [anime_list_df.user_id == 104129]

get_recommended_user(True)

!zip 'model.zip' '/notebooks/model_1_2' -r